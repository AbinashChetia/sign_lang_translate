{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of signs included: 36\n",
      "1: 1200\n",
      "2: 1200\n",
      "3: 1200\n",
      "4: 1200\n",
      "5: 1200\n",
      "6: 1200\n",
      "7: 1200\n",
      "8: 1200\n",
      "9: 1200\n",
      "A: 1200\n",
      "B: 1200\n",
      "C: 1200\n",
      "D: 1200\n",
      "E: 1200\n",
      "F: 1200\n",
      "G: 1200\n",
      "H: 1200\n",
      "I: 1200\n",
      "J: 1200\n",
      "K: 1200\n",
      "L: 1200\n",
      "M: 1200\n",
      "N: 1200\n",
      "O: 1200\n",
      "P: 1200\n",
      "Q: 1200\n",
      "R: 1200\n",
      "S: 1200\n",
      "T: 1200\n",
      "U: 1200\n",
      "V: 1200\n",
      "W: 1200\n",
      "X: 1200\n",
      "Y: 1200\n",
      "Z: 1200\n"
     ]
    }
   ],
   "source": [
    "isl_dir = './data/isl_data/'\n",
    "print(f'Number of signs included: {len(os.listdir(isl_dir))}')\n",
    "isl_signs = os.listdir(isl_dir)\n",
    "isl_signs.sort()\n",
    "for d in isl_signs:\n",
    "    if d == '.DS_Store':\n",
    "        continue\n",
    "    print(f'{d}: {len(os.listdir(os.path.join(isl_dir, d)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# initiating mediapipe configurations\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing image directory\n",
    "\n",
    "DATA_DIR = './data/gen_data'\n",
    "data_prefix = f'prep_data/{DATA_DIR.split(\"/\")[-1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "max_count = 20\n",
    "\n",
    "for dir_ in tqdm(os.listdir(DATA_DIR)):\n",
    "    if dir_ == '.DS_Store':\n",
    "        continue\n",
    "    count = 0\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x)\n",
    "                    data_aux.append(y)\n",
    "\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "        \n",
    "        count += 1\n",
    "        if count == max_count:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset stored at prep_data/gen_data_2023_10_21_11_32_16.pickle\n"
     ]
    }
   ],
   "source": [
    "now = dt.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "f = open(f'{data_prefix}_{now}.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "print(f'Dataset stored at {data_prefix}_{now}.pickle')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model - Random Forest Classifier (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing model directory\n",
    "\n",
    "DATA_LOC = 'prep_data/gen_data_2023_10_21_11_32_16.pickle'\n",
    "model_prefix = f'trained_models/{DATA_LOC.split(\"/\")[-1].split(\"_\")[0]}_model'\n",
    "\n",
    "# loading labelled dataset\n",
    "\n",
    "data_dict = pickle.load(open(DATA_LOC, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing data & label variables\n",
    "\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing...\n",
      "100.0% of samples classified correctly\n",
      "Model stored at trained_models/gen_model_2023_10_21_11_35_07.pickle\n"
     ]
    }
   ],
   "source": [
    "# training Random Forest Classifier model\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "print('Training...')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# testing the trained model\n",
    "\n",
    "print('Testing...')\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f'{accuracy_score(y_test, y_pred) * 100}% of samples classified correctly')\n",
    "\n",
    "# storing the model\n",
    "\n",
    "now = dt.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "f = open(f'{model_prefix}_{now}.pickle', 'wb')\n",
    "pickle.dump({'model': clf}, f)\n",
    "f.close()\n",
    "print(f'Model stored at {model_prefix}_{now}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
